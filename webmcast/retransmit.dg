import '/os'
import '/asyncio'

import '/cno'

import 'config'
import 'ebml/ffi'
import 'ebml/lib'
import 'gstreamer'
import 'templates'


on_chunk_cb = (ffi.def_extern error: -1) $ handle data size force ->
    queue = ffi.from_handle handle
    queue :: asyncio.Queue and not force and queue.qsize! >= config.MAX_ENQUEUED_FRAMES =>
        # if the queue overflows, we're already screwed -- the tcp buffer
        # is also full. it will take a while to clear.
        return -1
    queue.put_nowait $ bytes $ ffi.buffer data size
    return 0


Broadcast = subclass object where
    __init__ = self loop ->
        self.cobj = ffi.new 'struct broadcast *'
        self.done = asyncio.Event loop: loop
        lib.broadcast_start self.cobj
        None

    __del__ = self ->
        lib.broadcast_stop self.cobj

    put_nowait = self chunk ->
        # (the method is named this way for api compatibility with asyncio.Queue.)
        lib.broadcast_send self.cobj (ffi.new 'uint8_t[]' chunk) (len chunk)

    connect = async $ self queue skip_headers: False ->
        handle = ffi.new_handle queue
        slot = lib.broadcast_connect self.cobj lib.on_chunk_cb handle skip_headers
        except
            _ =>
                await self.done.wait!
                # not in `finally`. cancelling this coroutine and connecting the queue
                # to another broadcast should be a valid operation.
                queue.close!
            finally => lib.broadcast_disconnect self.cobj slot
        return None

    close = self ->
        self.done.set!


Recoder = subclass object where
    _GLIB_MAIN_LOOP = gstreamer.run_loop!

    __init__ = self rate loop ->
        self._out  = out  = Broadcast loop
        self._pipe = pipe = gstreamer.Pipeline _GLIB_MAIN_LOOP

        self._sink = pipe.make 'appsink'
        self._sink.set_property 'emit-signals' True
        self._sink_handle = self._sink.connect 'new-sample' $ sink ->
            sink.emit 'pull-sample' |>.data |> loop.call_soon_threadsafe out.put_nowait
            return gstreamer.OK

        muxer = pipe.make 'webmmux'
        muxer.set_property 'streamable' True
        muxer.link self._sink

        self._demuxer = pipe.make 'matroskademux'
        self._demuxer_handle = self._demuxer.connect 'pad-added' $ demuxer pad -> if
            pad.name.startswith 'video_' =>
                kind = pad.get_current_caps!.get_structure 0 |>.get_name!
                mux = muxer.request_pad (muxer.get_pad_template 'video_%u') pad.name
                out = pipe.make 'queue'
                out.get_static_pad 'src' |>.link mux
                enc = pipe.make $ if (kind == 'video/x-vp9' => 'vp9enc') (otherwise => 'vp8enc')
                enc.set_property 'keyframe-max-dist' 60
                enc.set_property 'deadline' 1
                enc.set_property 'end-usage' 1  # constant bitrate
                enc.set_property 'target-bitrate' $ rate * 8
                enc.link out
                inp = pipe.make $ if (kind == 'video/x-vp9' => 'vp9dec') (otherwise => 'vp8dec')
                inp.link enc
                pad.link $ inp.get_static_pad 'sink'
            pad.name.startswith 'audio_' =>
                # NOTE gstreamer 1.8 required for opus audio in webmmux
                mux = muxer.request_pad (muxer.get_pad_template 'audio_%u') pad.name
                out = pipe.make 'queue'
                out.get_static_pad 'src' |>.link mux
                pad.link $ out.get_static_pad 'sink'

        self._source = pipe.make 'appsrc'
        self._source.set_property 'max-bytes' 8192
        self._source.link self._demuxer
        pipe.start!
        None

    put_nowait = self chunk ->
        self._source.emit 'push-buffer' $ gstreamer.buffer chunk

    connect = self queue skip_headers: False ->
        self._out.connect queue skip_headers

    close = self ->
        self._source.emit 'end-of-stream'
        self._demuxer.disconnect self._demuxer_handle
        self._sink.disconnect self._sink_handle
        self._out.close!


_static_root = head (import 'static' pure).__path__
_streams = {}


root = async $ req ->
    req.template = templates.load

    req.path == '/' =>
        req.push 'GET' '/static/css/uikit.min.css'  req.accept_headers
        req.push 'GET' '/static/css/everything.css' req.accept_headers
        req.push 'GET' '/static/js/jquery.min.js'   req.accept_headers
        req.push 'GET' '/static/js/uikit.min.js'    req.accept_headers
        # TODO UI/auth nodes
        return await req.respond_with_error 501 [] 'There is no UI yet.'

    req.path.startswith '/error/' => except
        err =>
            return await req.respond_with_error (int $ req.path !! slice 7 None) [] None
        err :: ValueError =>
            return await req.respond_with_error 400 [] 'Error codes are numbers, silly.'

    req.path.startswith '/static/' =>
        return await req.respond_with_file $ os.path.join _static_root $ req.path !! slice 8 None

    req.path.startswith '/room/' and req.path.find '/' 6 == -1 =>
        stream_id = req.path !! slice 6 None
        return await req.respond_with_template 200 [] 'room.html' stream_id: stream_id

    req.path.startswith '/stream/' and req.path.find '/' 8 == -1 =>
        stream_id = req.path !! slice 8 None
        return await $ if
            req.wants_websocket           => signal   req stream_id
            req.method in ('GET', 'HEAD') => download req stream_id
            req.method in ('POST', 'PUT') => upload   req stream_id
            otherwise => req.respond_with_error 405 [('accept', 'GET, POST')] 'Do what now?'

    return await req.respond_with_error 404 [] None


upload = async $ req stream_id ->
    except
        err =>
            stream = _streams !! stream_id
            stream._collecting_task is None =>
                return await req.respond_with_error 403 [] 'Stream ID already taken.'
            stream._collecting_task.cancel!
            stream._collecting_task = None
        err :: KeyError =>
            stream = _streams !! stream_id = Broadcast req.conn.loop
            stream._websockets = set!
            stream._collecting_task = None
            # gstreamer sends each frame as a separate PUT request,
            # so bitrate calculation must be done across calls to `upload`
            stream.rate = 0
            stream.rvar = 0
            stream._rate_pending = 0
            stream._rate_updater = req.conn.loop.create_task
                where while True =>
                    await asyncio.sleep 1 loop: req.conn.loop
                    # exponentially weighted moving moments at a = 0.5
                    #     avg[n] = a * x + (1 - a) * avg[n - 1]
                    #     var[n] = a * (x - avg[n]) ** 2 / (1 - a) + (1 - a) * var[n - 1]
                    stream.rate += (stream._rate_pending - stream.rate) / 2
                    stream.rvar += (stream._rate_pending - stream.rate) ** 2 - stream.rvar / 2
                    stream._rate_pending = 0
    except
        _ =>
            while chunk = await req.payload.read 16384 =>
                stream._rate_pending += len chunk
                stream.put_nowait chunk =>
                    return await req.respond_with_error 400 [] 'Malformed EBML.'
            return await req.respond 204 [] b''
        finally =>
            stream._collecting_task = req.conn.loop.call_later config.MAX_DOWNTIME $ ->
                _streams !!~ stream_id
                stream.close!
                stream._rate_updater.cancel!
                stream._rate_updater = None
                stream._collecting_task = None


download = async $ req stream_id ->
    stream = _streams.get stream_id or return await req.respond_with_error 404 [] None
    output = cno.Channel loop: req.conn.loop
    writer = req.conn.loop.create_task $ stream.connect output
    # FIXME there's a reference loop involving the current frame somewhere?
    stream = None
    # force excess frames to stay in the queue, not in the write buffer
    req.conn.transport.set_write_buffer_limits 512 256
    except
        _ => return await req.respond 200
            list'
                'content-type', 'video/webm'
                'cache-control', 'no-cache'
            output
        finally => writer.cancel!


signal = async $ req stream_id ->
    stream = _streams.get stream_id or return await req.respond_with_error 404 [] None

    with io = await req.websocket! => except
        _ =>
            stream._websockets.add io
            task = req.conn.loop.create_task $ signal_loop req io stream stream_id
            await asyncio.wait [task, stream.done.wait!] return_when: asyncio.FIRST_COMPLETED
        finally =>
            stream._websockets.discard io
            task.cancel!


signal_loop = async $ req io stream stream_id ->
    async for msg in io =>
        # TODO signaled mode (see README)
        for p in stream._websockets => p.send msg
